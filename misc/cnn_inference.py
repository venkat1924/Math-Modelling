# -*- coding: utf-8 -*-
"""
Inverse ODE Parameter Recovery using a Neural Network (Improved Version)

This script trains a model (specifically a 1D Convolutional Neural Network)
to predict the 13 parameters of a prey-predator ODE system given a time
series trajectory (X(t), Y(t), Z(t)) generated by that system.

Key improvements:
- Parameter clipping during validation simulation for stability.
- Robust handling of ODE simulation failures during validation trajectory comparison.
- Increased CNN model capacity.
"""

import os
import time
import warnings
import argparse
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import List, Tuple, Dict, Optional

# Import core libraries
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from scipy.integrate import solve_ivp

# Suppress numerical integration warnings and potential deprecation warnings
# UserWarnings from LSODA (like t+h=t) will be suppressed.
# RuntimeWarnings (like overflow) will still appear if not caught, which is good for diagnostics.
warnings.filterwarnings('ignore', category=UserWarning, module='scipy.integrate._ivp.lsoda')
warnings.filterwarnings('ignore', category=FutureWarning)


# Define global constants
PARAM_NAMES = ['r', 'p1', 'p2', 'd1', 'b', 'c1', 'a', 'm',
               'h1', 'd2', 'd3', 'lambda1', 'q']
NUM_PARAMS = len(PARAM_NAMES)
STATE_VARIABLES = ['X', 'Y', 'Z']
NUM_STATE_VARIABLES = len(STATE_VARIABLES)

# Define known parameter ranges from the simulation script
# This is crucial for clipping predicted parameters during validation simulations
PARAMETER_RANGES = {
    'r': [0.1, 2.0], 'p1': [0.0, 0.4], 'p2': [0.1, 0.3],
    'd1': [0.05, 0.1], 'b': [0.01, 0.05], 'c1': [0.1, 0.2],
    'a': [0.5, 1.0], 'm': [0.0, 0.1], 'h1': [0.2, 0.3],
    'd2': [0.05, 0.1], 'd3': [0.02, 0.05], 'lambda1': [0.5, 1.0],
    'q': [0.5, 1.0]
}
# Ensure PARAM_NAMES order is consistent with PARAMETER_RANGES for clipping
PARAMETER_BOUNDS_MIN = np.array([PARAMETER_RANGES[name][0] for name in PARAM_NAMES], dtype=np.float32)
PARAMETER_BOUNDS_MAX = np.array([PARAMETER_RANGES[name][1] for name in PARAM_NAMES], dtype=np.float32)

DEFAULT_TRAJ_FAIL_PENALTY = 1e6 # High penalty for failed trajectory simulations

# Set random seed for reproducibility
SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


# --- Chain-of-Thought: ODE Simulation Utilities ---
# Reasoning: (Same as before) To validate the predicted parameters, we need the ability to
# simulate the ODE system.
# Improvement: Added parameter clipping within `integrate_ode` when using predicted parameters
# to enhance solver stability.

def ode_system(t: float, state: np.ndarray, params_dict: Dict[str, float]) -> List[float]:
    """
    Defines the ODE system dynamics.
    (No changes to the core ODE definition itself)
    """
    X, Y, Z = state
    p = params_dict

    denominator1 = max(1 + p['p1']*Y + p['p2']*Z, 1e-12)
    denominator2 = max(p['a'] + (1 - p['m'])*X, 1e-12)
    one_minus_m = 1 - p['m']

    # Catch potential overflows before they happen if X,Y,Z get too large
    # This is an aggressive safeguard if X, Y, Z values become astronomically large.
    # It's better if the solver handles this or parameters are well-behaved.
    if not (np.isfinite(X) and np.isfinite(Y) and np.isfinite(Z)):
        # Return large derivatives to signal instability if solve_ivp doesn't catch it
        return [1e12] * 3
    if X > 1e9 or Y > 1e9 or Z > 1e9: # If populations explode
        # Attempt to return high negative gradient if positive, or zero
        # This is a heuristic and might not always be stable
        # For example, if X is huge, make dXdt strongly negative
        return [-abs(X)*1e3 if X > 1e9 else 0,
                -abs(Y)*1e3 if Y > 1e9 else 0,
                -abs(Z)*1e3 if Z > 1e9 else 0]


    try:
        dXdt = (p['r'] * X / denominator1) \
               - p['d1']*X \
               - p['b']*X**2 \
               - (p['c1']*one_minus_m*X*(Y + p['q']*Z) / denominator2)

        dYdt = (p['h1']*one_minus_m*X*(Y + p['q']*Z) / denominator2) \
               - p['d2']*Y \
               - p['lambda1']*Y*Z

        dZdt = p['lambda1']*Y*Z \
               - (p['d2'] + p['d3'])*Z
    except OverflowError:
        # If an overflow occurs during calculation, return large values
        # to signal solver to reduce step size or indicate instability.
        return [1e12] * 3


    return [dXdt, dYdt, dZdt]

def integrate_ode(t_span: Tuple[float, float],
                  y0: np.ndarray,
                  params_values: np.ndarray, # These are UNCLIPPED if coming from NN
                  t_eval: Optional[np.ndarray] = None,
                  param_names: List[str] = PARAM_NAMES,
                  apply_bounds: bool = True) -> Optional[pd.DataFrame]: # New flag
    """
    Integrates the ODE system.
    Improvement: Clips params_values to predefined PARAMETER_BOUNDS
                 if apply_bounds is True (e.g., for predicted parameters).
    """
    if len(params_values) != len(param_names):
        raise ValueError("Length of params_values must match length of param_names.")

    # --- Parameter Clipping (New) ---
    # Clip predicted parameters to be within the known valid ranges
    # This is crucial for stabilizing ODE solving with potentially noisy NN outputs.
    if apply_bounds:
        params_values_clipped = np.clip(params_values, PARAMETER_BOUNDS_MIN, PARAMETER_BOUNDS_MAX)
    else:
        params_values_clipped = params_values

    params_dict = dict(zip(param_names, params_values_clipped))

    try:
        sol = solve_ivp(
            fun=lambda t, y: ode_system(t, y, params_dict),
            t_span=t_span,
            y0=y0,
            method='LSODA',
            t_eval=t_eval,
            rtol=1e-6, # Relative tolerance
            atol=1e-8, # Absolute tolerance
            # first_step=None, # Let solver determine
            # max_step=t_span[1]/100 # Limit max step size
        )

        if sol.success:
            df = pd.DataFrame({
                't': sol.t,
                'X': sol.y[0],
                'Y': sol.y[1],
                'Z': sol.y[2]
            })
            df[STATE_VARIABLES] = df[STATE_VARIABLES].clip(lower=0) # Ensure non-negativity
            return df
        else:
            # print(f"ODE integration failed: {sol.message} for params {params_dict}") # Debug
            return None
    except Exception as e:
        # print(f"Exception during ODE integration with params {params_dict}: {e}") # Debug
        return None

# --- Chain-of-Thought: Data Loading and Preprocessing ---
# Reasoning: (Same as before)
# ODESimulationDataset class remains largely the same in its core logic.

class ODESimulationDataset(Dataset):
    """ PyTorch Dataset for loading ODE simulation data. (Largely unchanged) """
    def __init__(self,
                 csv_path: str,
                 param_names: List[str],
                 state_variables: List[str],
                 param_scaler: Optional[MinMaxScaler] = None,
                 fit_scaler: bool = False,
                 use_noisy_data: bool = True):
        super().__init__()
        self.param_names = param_names
        self.state_variables = state_variables
        self.use_noisy_data = use_noisy_data
        self.input_cols = [f"{v}_noisy" if use_noisy_data else v for v in state_variables]

        print(f"Loading data from {csv_path}...")
        try:
            self.data_df = pd.read_csv(csv_path)
        except FileNotFoundError:
            raise FileNotFoundError(f"Data file not found at {csv_path}")
        except Exception as e:
            raise RuntimeError(f"Error loading CSV {csv_path}: {e}")

        required_cols = ['run_id', 't'] + self.input_cols + self.param_names
        missing_cols = [col for col in required_cols if col not in self.data_df.columns]
        if missing_cols:
            raise ValueError(f"Missing required columns in CSV: {missing_cols}")

        print("Processing and grouping data by run_id...")
        self.trajectories = []
        self.parameters = []
        self.run_ids = self.data_df['run_id'].unique()

        grouped = self.data_df.groupby('run_id')
        for run_id in self.run_ids:
            run_data = grouped.get_group(run_id)
            trajectory = run_data[self.input_cols].values
            params = run_data[self.param_names].iloc[0].values
            self.trajectories.append(trajectory)
            self.parameters.append(params)

        self.parameters = np.array(self.parameters, dtype=np.float32)
        self.trajectories = np.array(self.trajectories, dtype=np.float32)

        print(f"Found {len(self.run_ids)} unique runs.")
        if self.trajectories.shape[0] == 0:
             raise ValueError("No valid runs found in the dataset.")
        self.num_timesteps = self.trajectories.shape[1]
        self.num_variables = self.trajectories.shape[2]
        print(f"Trajectory shape: (Runs, Timesteps, Variables) = {self.trajectories.shape}")

        if fit_scaler:
            if param_scaler is not None:
                print("Warning: fit_scaler=True but a param_scaler was provided. Using the provided scaler.")
            else:
                print("Fitting new MinMaxScaler on parameters...")
                self.param_scaler = MinMaxScaler(feature_range=(0, 1)) # Scale to [0,1]
                self.scaled_parameters = self.param_scaler.fit_transform(self.parameters)
        elif param_scaler is not None:
            print("Using provided parameter scaler...")
            self.param_scaler = param_scaler
            self.scaled_parameters = self.param_scaler.transform(self.parameters)
        else:
            print("Warning: No parameter scaling applied during initialization.")
            self.param_scaler = None
            self.scaled_parameters = self.parameters

        print("Normalizing trajectories (standardization per run)...")
        self.trajectory_scalers = [StandardScaler() for _ in range(len(self.trajectories))]
        self.normalized_trajectories = np.array([
            scaler.fit_transform(traj) for scaler, traj in zip(self.trajectory_scalers, self.trajectories)
        ], dtype=np.float32)
        
        self.normalized_trajectories = np.transpose(self.normalized_trajectories, (0, 2, 1))
        print(f"Final trajectory tensor shape for model: {self.normalized_trajectories.shape}")


    def __len__(self) -> int:
        return len(self.run_ids)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        trajectory_tensor = torch.from_numpy(self.normalized_trajectories[idx])
        params_tensor = torch.from_numpy(self.scaled_parameters[idx])
        return trajectory_tensor, params_tensor

    def get_original_params(self, idx: int) -> np.ndarray:
        return self.parameters[idx]

    def get_run_id(self, idx: int) -> int:
        return self.run_ids[idx]

# --- Chain-of-Thought: Model Architecture ---
# Reasoning: (Same as before) 1D CNN is a good choice.
# Improvement: Increased model capacity (more filters, more FC units, potentially deeper).

class ParameterPredictorCNN(nn.Module):
    """
    1D CNN model to predict ODE parameters from time series trajectories.
    Increased capacity.
    Input shape: (BatchSize, NumStateVariables, NumTimesteps)
    Output shape: (BatchSize, NumParams)
    """
    def __init__(self, num_params: int = NUM_PARAMS,
                 num_state_variables: int = NUM_STATE_VARIABLES,
                 num_timesteps: int = 1000):
        super().__init__()
        self.num_params = num_params
        self.num_state_variables = num_state_variables

        self.conv_layers = nn.Sequential(
            # Layer 1
            nn.Conv1d(num_state_variables, 64, kernel_size=7, padding=3), # 3 -> 64 channels
            nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(kernel_size=2, stride=2), # L / 2

            # Layer 2
            nn.Conv1d(64, 128, kernel_size=5, padding=2), # 64 -> 128
            nn.BatchNorm1d(128), nn.ReLU(), nn.MaxPool1d(kernel_size=2, stride=2), # L / 4

            # Layer 3
            nn.Conv1d(128, 256, kernel_size=3, padding=1), # 128 -> 256
            nn.BatchNorm1d(256), nn.ReLU(), nn.MaxPool1d(kernel_size=2, stride=2), # L / 8

            # Layer 4
            nn.Conv1d(256, 512, kernel_size=3, padding=1), # 256 -> 512
            nn.BatchNorm1d(512), nn.ReLU(), nn.MaxPool1d(kernel_size=2, stride=2), # L / 16
            
            # Layer 5 (New)
            nn.Conv1d(512, 512, kernel_size=3, padding=1), # 512 -> 512
            nn.BatchNorm1d(512), nn.ReLU(), nn.MaxPool1d(kernel_size=2, stride=2)  # L / 32
        )

        # Recalculate flattened size after 5 MaxPool layers
        conv_output_length = num_timesteps // (2**5) # e.g., 1000 / 32 = 31
        flat_features = 512 * conv_output_length

        self.fc_layers = nn.Sequential(
            nn.Flatten(),
            nn.Linear(flat_features, 1024), # Increased
            nn.ReLU(), nn.Dropout(0.5),
            nn.Linear(1024, 512), # Increased
            nn.ReLU(), nn.Dropout(0.3),
            nn.Linear(512, num_params)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.conv_layers(x)
        x = self.fc_layers(x)
        return x

# --- Chain-of-Thought: Training and Validation Loop ---
# Reasoning: (Same as before)
# Improvement: `validate_epoch` now handles trajectory simulation failures more robustly
# by assigning a penalty, making `val_trajectory_mse` more representative of issues.

def train_epoch(model: nn.Module, dataloader: DataLoader, optimizer: optim.Optimizer,
                criterion: nn.Module, device: torch.device) -> float:
    """ Performs one epoch of training. (Unchanged) """
    model.train()
    total_loss = 0.0
    for inputs, targets in dataloader:
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        predictions = model(inputs)
        loss = criterion(predictions, targets)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(dataloader)


def validate_epoch(model: nn.Module, dataloader: DataLoader, criterion: nn.Module,
                   param_scaler: MinMaxScaler, device: torch.device,
                   full_dataset: Optional[ODESimulationDataset] = None,
                   num_trajectory_comps: int = 0,
                   t_span_eval: Optional[Tuple[float, float]] = None,
                   t_eval_points: Optional[np.ndarray] = None,
                   trajectory_fail_penalty: float = DEFAULT_TRAJ_FAIL_PENALTY
                   ) -> Tuple[float, Dict[str, float]]:
    """
    Performs one epoch of validation.
    Improvement: Assigns `trajectory_fail_penalty` if ODE simulation fails or gives
                 mismatched length during trajectory comparison.
    """
    model.eval()
    total_scaled_loss = 0.0
    total_unscaled_mae = 0.0
    sum_trajectory_mse = 0.0 # Sum of MSEs or penalties
    num_trajectory_comps_attempted = 0 # Denominator for avg_trajectory_mse
    num_samples = 0

    val_metrics = {}

    with torch.no_grad():
        for batch_idx, (inputs, targets_scaled) in enumerate(dataloader):
            batch_size = inputs.size(0)
            num_samples += batch_size
            inputs, targets_scaled = inputs.to(device), targets_scaled.to(device)

            predictions_scaled = model(inputs)
            scaled_loss = criterion(predictions_scaled, targets_scaled)
            total_scaled_loss += scaled_loss.item() * batch_size

            try:
                original_indices = []
                if hasattr(dataloader.sampler, 'indices'): # Handles SubsetRandomSampler
                    start_idx = batch_idx * dataloader.batch_size
                    end_idx = start_idx + batch_size
                    original_indices = dataloader.sampler.indices[start_idx:end_idx]
                else: # Fallback for sequential or other samplers
                     original_indices = list(range(num_samples - batch_size, num_samples))

                preds_unscaled_np = param_scaler.inverse_transform(predictions_scaled.cpu().numpy())
                
                if full_dataset:
                    targets_unscaled_np = np.array([full_dataset.get_original_params(i) for i in original_indices])
                    unscaled_mae = np.mean(np.abs(preds_unscaled_np - targets_unscaled_np))
                    total_unscaled_mae += unscaled_mae * batch_size
                else: # Should not happen if full_dataset is passed
                    total_unscaled_mae += np.nan # Mark as invalid

                # --- Trajectory Comparison ---
                if full_dataset and num_trajectory_comps > 0 and \
                   num_trajectory_comps_attempted < num_trajectory_comps:
                    if t_span_eval is None or t_eval_points is None:
                        print("Warning: Skipping trajectory comparison, t_span_eval or t_eval_points not provided.")
                    else:
                        comps_to_attempt_in_batch = min(batch_size, num_trajectory_comps - num_trajectory_comps_attempted)
                        for i in range(comps_to_attempt_in_batch):
                            orig_idx = original_indices[i]
                            original_traj_unnorm = full_dataset.trajectories[orig_idx] # (T, V)
                            y0 = original_traj_unnorm[0, :] # Initial conditions
                            predicted_params_single = preds_unscaled_np[i, :]

                            simulated_df = integrate_ode(
                                t_span=t_span_eval, y0=y0,
                                params_values=predicted_params_single, # Clipped inside integrate_ode
                                t_eval=t_eval_points, param_names=PARAM_NAMES,
                                apply_bounds=True # IMPORTANT: ensure predicted params are clipped
                            )
                            num_trajectory_comps_attempted += 1

                            if simulated_df is not None:
                                simulated_traj = simulated_df[STATE_VARIABLES].values
                                if len(simulated_traj) == len(original_traj_unnorm):
                                    traj_mse = np.mean((original_traj_unnorm - simulated_traj)**2)
                                    sum_trajectory_mse += traj_mse
                                else: # Length mismatch
                                    sum_trajectory_mse += trajectory_fail_penalty
                            else: # Simulation failed (returned None)
                                sum_trajectory_mse += trajectory_fail_penalty
            except Exception as e:
                 print(f"\nError during validation metric calculation (batch {batch_idx}): {e}")
                 total_unscaled_mae += np.nan * batch_size


    avg_scaled_loss = total_scaled_loss / num_samples if num_samples > 0 else 0
    avg_unscaled_mae = total_unscaled_mae / num_samples if num_samples > 0 else 0

    val_metrics['val_loss_scaled'] = avg_scaled_loss
    val_metrics['val_mae_unscaled'] = avg_unscaled_mae

    if num_trajectory_comps_attempted > 0:
         avg_trajectory_mse = sum_trajectory_mse / num_trajectory_comps_attempted
         val_metrics['val_trajectory_mse'] = avg_trajectory_mse

    return avg_scaled_loss, val_metrics


# --- Chain-of-Thought: Utility Functions ---
# Reasoning: (Same as before)
# `save_checkpoint`, `load_checkpoint`, `plot_curves`, `save_results` are largely unchanged.

def save_checkpoint(epoch: int, model: nn.Module, optimizer: optim.Optimizer,
                    param_scaler: MinMaxScaler, loss: float, filepath: str):
    """ Saves model checkpoint. (Unchanged) """
    print(f"Saving checkpoint to {filepath}...")
    state = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'param_scaler': param_scaler,
        'loss': loss,
    }
    torch.save(state, filepath)
    print("Checkpoint saved.")

def load_checkpoint(filepath: str, model: nn.Module,
                    optimizer: Optional[optim.Optimizer] = None,
                    device: Optional[torch.device] = None
                    ) -> Tuple[int, float, MinMaxScaler]:
    """ Loads model checkpoint. (Unchanged) """
    if not os.path.exists(filepath):
        raise FileNotFoundError(f"Checkpoint file not found: {filepath}")
    if device is None:
         device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Loading checkpoint from {filepath}...")
    checkpoint = torch.load(filepath, map_location=device, weights_only=False)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    if optimizer and 'optimizer_state_dict' in checkpoint:
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        for state_val in optimizer.state.values(): # Corrected variable name
            for k, v in state_val.items():
                if isinstance(v, torch.Tensor):
                    state_val[k] = v.to(device)
    start_epoch = checkpoint.get('epoch', 0) + 1
    best_loss = checkpoint.get('loss', float('inf'))
    param_scaler = checkpoint.get('param_scaler', None)
    if param_scaler is None:
         print("Warning: Parameter scaler not found in checkpoint.")
    print(f"Checkpoint loaded. Resuming from Epoch {start_epoch}. Previous best loss: {best_loss:.4f}")
    return start_epoch, best_loss, param_scaler


def plot_curves(history: Dict[str, List[float]], save_path: Optional[str] = None):
    """ Plots training and validation loss curves. (Modified to handle potential val_trajectory_mse) """
    num_plots = 2
    if 'val_trajectory_mse' in history and any(not np.isnan(m) for m in history['val_trajectory_mse'] if m is not None):
        num_plots = 3
        
    plt.figure(figsize=(6 * num_plots, 5))

    plt.subplot(1, num_plots, 1)
    if 'train_loss' in history:
        plt.plot(history['train_loss'], label='Training Loss (Scaled)')
    if 'val_loss_scaled' in history:
        plt.plot(history['val_loss_scaled'], label='Validation Loss (Scaled)')
    plt.title('Scaled Parameter Loss')
    plt.xlabel('Epoch'); plt.ylabel('Loss (MSE)'); plt.legend(); plt.grid(True)

    plt.subplot(1, num_plots, 2)
    if 'val_mae_unscaled' in history:
         valid_mae = [m for m in history['val_mae_unscaled'] if m is not None and not np.isnan(m)]
         if valid_mae:
              plt.plot(range(len(history['val_mae_unscaled'])), history['val_mae_unscaled'], label='Validation MAE (Unscaled)', marker='.')
              plt.title('Unscaled Parameter MAE')
              plt.xlabel('Epoch'); plt.ylabel('Mean Absolute Error'); plt.legend(); plt.grid(True)
         else:
              plt.text(0.5, 0.5, 'No valid unscaled\nMAE data', ha='center', va='center', transform=plt.gca().transAxes)
              plt.title('Unscaled Parameter MAE')
    else:
         plt.text(0.5, 0.5, 'No unscaled\nMAE data', ha='center', va='center', transform=plt.gca().transAxes)
         plt.title('Unscaled Parameter MAE')
         
    if num_plots == 3:
        plt.subplot(1, num_plots, 3)
        if 'val_trajectory_mse' in history:
            valid_traj_mse = [m for m in history['val_trajectory_mse'] if m is not None and not np.isnan(m)]
            if valid_traj_mse:
                plt.plot(range(len(history['val_trajectory_mse'])), history['val_trajectory_mse'], label='Validation Trajectory MSE', marker='.')
                plt.title('Validation Trajectory MSE')
                plt.xlabel('Epoch'); plt.ylabel('Mean Squared Error'); plt.legend(); plt.grid(True)
                plt.yscale('log') # Trajectory MSE can be large, log scale often helps
            else:
                plt.text(0.5, 0.5, 'No valid trajectory\nMSE data', ha='center', va='center', transform=plt.gca().transAxes)
                plt.title('Validation Trajectory MSE')
        else:
            plt.text(0.5, 0.5, 'No trajectory\nMSE data', ha='center', va='center', transform=plt.gca().transAxes)
            plt.title('Validation Trajectory MSE')

    plt.tight_layout()
    if save_path:
        print(f"Saving plot to {save_path}...")
        plt.savefig(save_path)
        print("Plot saved.")
    plt.show(block=False) # Non-blocking show
    plt.pause(1) # Allow plot to render


def save_results(results_df: pd.DataFrame, filepath: str):
    """ Saves predictions or metrics to a CSV file. (Unchanged) """
    print(f"Saving results to {filepath}...")
    try:
        results_df.to_csv(filepath, index=False)
        print("Results saved.")
    except Exception as e:
        print(f"Error saving results to {filepath}: {e}")


# --- Chain-of-Thought: Main Execution Block ---
# Reasoning: (Same as before)
# Improvement: Added `trajectory_fail_penalty` argument.

def main(args):
    """ Main execution function. """
    start_time = time.time()
    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir); print(f"Created output directory: {args.output_dir}")

    device = torch.device("cuda" if torch.cuda.is_available() and not args.no_gpu else "cpu")
    print(f"Using device: {device}")

    best_model_path = os.path.join(args.output_dir, "best_model2.pth")
    last_model_path = os.path.join(args.output_dir, "last_model2.pth")
    plot_path = os.path.join(args.output_dir, "training_curves.png")
    results_path = os.path.join(args.output_dir, "validation_results.csv")

    print("Loading and splitting data...")
    try:
        full_dataset_info = ODESimulationDataset(
            csv_path=args.data_path, param_names=PARAM_NAMES,
            state_variables=STATE_VARIABLES, param_scaler=None, fit_scaler=False,
            use_noisy_data=not args.use_clean_data
        )
    except (FileNotFoundError, ValueError, RuntimeError) as e:
        print(f"Error initializing dataset: {e}"); return

    num_runs = len(full_dataset_info)
    indices = list(range(num_runs))
    train_indices, val_indices = train_test_split(
        indices, test_size=args.val_split, random_state=SEED, shuffle=True
    )
    print(f"Total runs: {num_runs}, Training: {len(train_indices)}, Validation: {len(val_indices)}")

    print("Fitting parameter scaler on training data...")
    train_params = full_dataset_info.parameters[train_indices]
    param_scaler = MinMaxScaler(feature_range=(0, 1))
    param_scaler.fit(train_params)
    print("Scaler fitted.")
    
    # Apply fitted scaler to the entire dataset's parameter copy for use in __getitem__
    full_dataset_info.param_scaler = param_scaler
    full_dataset_info.scaled_parameters = param_scaler.transform(full_dataset_info.parameters)


    train_sampler = SubsetRandomSampler(train_indices)
    val_sampler = SubsetRandomSampler(val_indices)
    train_loader = DataLoader(full_dataset_info, batch_size=args.batch_size, sampler=train_sampler,
                              num_workers=args.num_workers, pin_memory=device.type == 'cuda')
    val_loader = DataLoader(full_dataset_info, batch_size=args.batch_size, sampler=val_sampler,
                            num_workers=args.num_workers, pin_memory=device.type == 'cuda')

    num_timesteps = full_dataset_info.num_timesteps

    print("Initializing model, optimizer, and loss...")
    model = ParameterPredictorCNN(num_params=NUM_PARAMS,
                                  num_state_variables=NUM_STATE_VARIABLES,
                                  num_timesteps=num_timesteps).to(device)
    print(f"Model architecture:\n{model}")
    print(f"Total trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")

    optimizer = optim.AdamW(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)
    criterion = nn.MSELoss()
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.1, patience=args.scheduler_patience, verbose=True
    ) if args.use_scheduler else None
    if scheduler: print("Using ReduceLROnPlateau LR scheduler.")


    print("Starting training...")
    history = {
        'train_loss': [], 'val_loss_scaled': [], 'val_mae_unscaled': [], 'val_trajectory_mse': []
    }
    best_val_loss = float('inf') # This tracks val_loss_scaled for early stopping
    epochs_no_improve = 0
    start_epoch = 0

    if args.resume_from:
        try:
            start_epoch, best_val_loss, loaded_scaler = load_checkpoint(
                args.resume_from, model, optimizer, device
            )
            if loaded_scaler:
                 param_scaler = loaded_scaler
                 full_dataset_info.param_scaler = param_scaler # Ensure consistency
                 full_dataset_info.scaled_parameters = param_scaler.transform(full_dataset_info.parameters)
                 print("Parameter scaler loaded and applied from checkpoint.")
            else:
                 print("Warning: Could not load parameter scaler from checkpoint. Using newly fitted one.")
        except FileNotFoundError: print(f"Checkpoint {args.resume_from} not found. Starting fresh.")
        except Exception as e: print(f"Error loading checkpoint {args.resume_from}: {e}. Starting fresh.")

    # Use actual time points from the dataset for trajectory evaluation
    first_run_id = full_dataset_info.run_ids[0]
    t_values_for_first_run = full_dataset_info.data_df[full_dataset_info.data_df['run_id'] == first_run_id]['t']
    t_span_eval = (t_values_for_first_run.min(), t_values_for_first_run.max())
    t_eval_points = t_values_for_first_run.unique() # Ensure unique, sorted time points
    t_eval_points.sort()


    for epoch in range(start_epoch, args.epochs):
        epoch_start_time = time.time()
        print(f"\n--- Epoch {epoch+1}/{args.epochs} ---")

        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)
        history['train_loss'].append(train_loss)
        print(f"Epoch {epoch+1} Training Loss (Scaled): {train_loss:.6f}")

        val_loss_scaled, val_metrics = validate_epoch(
            model, val_loader, criterion, param_scaler, device,
            full_dataset=full_dataset_info, num_trajectory_comps=args.num_traj_comps,
            t_span_eval=t_span_eval, t_eval_points=t_eval_points,
            trajectory_fail_penalty=args.trajectory_fail_penalty
        )
        history['val_loss_scaled'].append(val_metrics['val_loss_scaled'])
        history['val_mae_unscaled'].append(val_metrics.get('val_mae_unscaled', np.nan))
        history['val_trajectory_mse'].append(val_metrics.get('val_trajectory_mse', np.nan))

        print(f"Epoch {epoch+1} Validation Loss (Scaled): {val_metrics['val_loss_scaled']:.6f}")
        if 'val_mae_unscaled' in val_metrics:
            print(f"Epoch {epoch+1} Validation MAE (Unscaled): {val_metrics['val_mae_unscaled']:.6f}")
        if 'val_trajectory_mse' in val_metrics:
            print(f"Epoch {epoch+1} Validation Trajectory MSE: {val_metrics['val_trajectory_mse']:.6f}")

        print(f"Epoch duration: {time.time() - epoch_start_time:.2f} seconds")

        if scheduler: scheduler.step(val_metrics['val_loss_scaled'])

        current_primary_val_loss = val_metrics['val_loss_scaled'] # Early stopping based on this
        if current_primary_val_loss < best_val_loss:
            print(f"Val loss improved ({best_val_loss:.6f} --> {current_primary_val_loss:.6f}). Saving best model...")
            best_val_loss = current_primary_val_loss
            save_checkpoint(epoch, model, optimizer, param_scaler, best_val_loss, best_model_path)
            epochs_no_improve = 0
        else:
            epochs_no_improve += 1
            print(f"Val loss did not improve for {epochs_no_improve} epoch(s).")

        save_checkpoint(epoch, model, optimizer, param_scaler, current_primary_val_loss, last_model_path)

        if epochs_no_improve >= args.patience:
            print(f"\nEarly stopping triggered after {args.patience} epochs without improvement.")
            break

    print(f"\n--- Training Finished --- Total time: {time.time() - start_time:.2f}s")
    print(f"Best validation loss (scaled parameter MSE): {best_val_loss:.6f}")

    print("\nLoading best model for final evaluation...")
    try:
        _, _, final_scaler = load_checkpoint(best_model_path, model, device=device)
        if final_scaler is None: final_scaler = param_scaler

        print("Generating final predictions on validation set...")
        model.eval()
        all_preds_unscaled, all_targets_unscaled, all_run_ids = [], [], []
        with torch.no_grad():
            for batch_idx, (inputs, _) in enumerate(val_loader): # Targets not strictly needed here
                inputs = inputs.to(device)
                predictions_scaled = model(inputs)
                preds_unscaled = final_scaler.inverse_transform(predictions_scaled.cpu().numpy())
                
                original_indices = [] # Logic to get original indices from val_loader sampler
                batch_size = inputs.size(0)
                if hasattr(val_loader.sampler, 'indices'):
                    start_idx = batch_idx * val_loader.batch_size
                    end_idx = start_idx + batch_size
                    original_indices = val_loader.sampler.indices[start_idx:end_idx]
                else:
                     num_processed = batch_idx * val_loader.batch_size
                     original_indices = list(range(num_processed, num_processed + batch_size))
                
                targets_unscaled = np.array([full_dataset_info.get_original_params(i) for i in original_indices])
                run_ids = [full_dataset_info.get_run_id(i) for i in original_indices]

                all_preds_unscaled.append(preds_unscaled)
                all_targets_unscaled.append(targets_unscaled)
                all_run_ids.extend(run_ids)

        final_predictions = np.concatenate(all_preds_unscaled, axis=0)
        final_targets = np.concatenate(all_targets_unscaled, axis=0)
        results_data = {'run_id': all_run_ids}
        for i, name in enumerate(PARAM_NAMES):
            results_data[f'target_{name}'] = final_targets[:, i]
            results_data[f'predicted_{name}'] = final_predictions[:, i]
            results_data[f'error_{name}'] = final_predictions[:, i] - final_targets[:, i]
        results_df = pd.DataFrame(results_data)
        save_results(results_df, results_path)
    except FileNotFoundError: print(f"Best model {best_model_path} not found. Skipping final eval.")
    except Exception as e: print(f"Error in final evaluation: {e}")

    print("\nPlotting training curves...")
    plot_curves(history, plot_path)
    print("\nScript finished.")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Train an inverse model for ODE parameter recovery.")
    parser.add_argument('--data_path', type=str, default = 'simulation_results.csv', help="Path to simulation CSV.")
    parser.add_argument('--output_dir', type=str, default="./ode_inverse_output_v2", help="Output directory.")
    parser.add_argument('--use_clean_data', action='store_true', help="Use clean X,Y,Z data.")
    parser.add_argument('--epochs', type=int, default=100, help="Max training epochs.")
    parser.add_argument('--batch_size', type=int, default=64, help="Batch size.")
    parser.add_argument('--learning_rate', type=float, default=1e-4, help="Learning rate.")
    parser.add_argument('--weight_decay', type=float, default=1e-5, help="Weight decay.")
    parser.add_argument('--val_split', type=float, default=0.2, help="Validation split fraction.")
    parser.add_argument('--patience', type=int, default=15, help="Early stopping patience.") # Increased patience
    parser.add_argument('--use_scheduler', action='store_true', help="Use ReduceLROnPlateau scheduler.")
    parser.add_argument('--scheduler_patience', type=int, default=7, help="Patience for LR scheduler.") # Increased
    parser.add_argument('--num_workers', type=int, default=min(4, os.cpu_count() if os.cpu_count() else 1), help="DataLoader workers.")
    parser.add_argument('--no_gpu', action='store_true', help="Disable GPU.")
    parser.add_argument('--resume_from', type=str, default=None, help="Checkpoint path to resume.")
    parser.add_argument('--num_traj_comps', type=int, default=5, help="Number of trajectory comparisons in validation.")
    parser.add_argument('--trajectory_fail_penalty', type=float, default=DEFAULT_TRAJ_FAIL_PENALTY,
                        help="Penalty for failed trajectory simulation during validation.")
    args = parser.parse_args()
    main(args)